# Техническое задание на позицию: Junior Python разработчик

## a. Что было сделано

Спарсил цитаты со всех страниц [сайта](https://quotes.toscrape.com) и сохранил в [quotes.json](quotes.json).

## b. Откуда были получены данные

С html документа каждой из страниц.

## c. Как осуществлялся сбор

Использовал requests для получения html документа страницы, затем с помощью BeautifulSoup прошёл по нужным элементам, чтобы достать автора, текст и тэги. На каждой итерации добавлял полученную информацию в список, после этого сделал дамп списка в json.

## d. Почему был выбран тот или иной метод/инструмент, а не другой

requests - базовая библиотека для любых http запросов, соответственно она позволила сделать GET запрос к серверу и получить html документ страницы.
BeautifulSoup же самая распространённая библиотека для парсинга.